{"cells":[{"cell_type":"markdown","metadata":{"id":"PudqcfqVpo8r"},"source":["<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%202%20-%20Custom%20Training%20loops%2C%20Gradients%20and%20Distributed%20Training/Week%204%20-%20Distribution%20Strategy/C2_W4_Lab_2_multi-GPU-mirrored-strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"ZAV94Uv1po85"},"source":["# Multi-GPU Mirrored Strategy\n","\n","In this ungraded lab, you'll go through how to set up a Multi-GPU Mirrored Strategy. The lab environment only has a CPU but we placed the code here in case you want to try this out for yourself in a multiGPU device.\n","\n","**Notes:** \n","- If you are running this on Coursera, you'll see it gives a warning about no presence of GPU devices. \n","- If you are running this in Colab, make sure you have selected your `runtime` to be `GPU`. \n","- In both these cases, you'll see there's only 1 device that is available.  \n","- One device is sufficient for helping you understand these distribution strategies."]},{"cell_type":"markdown","metadata":{"id":"W4qG49Unpo87"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XBJkDYqBpo88","executionInfo":{"status":"ok","timestamp":1643272144294,"user_tz":-420,"elapsed":3806,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"8cUb7BQMpo9A"},"source":["## Setup Distribution Strategy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QN6mmN7po9C","executionInfo":{"status":"ok","timestamp":1643272148036,"user_tz":-420,"elapsed":509,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}},"outputId":"91b4d5ec-af75-4b60-ccb4-e983fb8854a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","Number of devices: 1\n"]}],"source":["# Note that it generally has a minimum of 8 cores, but if your GPU has\n","# less, you need to set this. In this case one of my GPUs has 4 cores\n","os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n","\n","# If the list of devices is not specified in the\n","# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n","# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n","strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n","print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"]},{"cell_type":"markdown","metadata":{"id":"QoxzXnvYpo9E"},"source":["## Prepare the Data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy5mkGw8po9G","executionInfo":{"status":"ok","timestamp":1643272150667,"user_tz":-420,"elapsed":2661,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}},"outputId":"14482375-5ba5-45e2-8465-f36dd6c9fc06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}],"source":["# Get the data\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# Adding a dimension to the array -> new shape == (28, 28, 1)\n","# We are doing this because the first layer in our model is a convolutional\n","# layer and it requires a 4D input (batch_size, height, width, channels).\n","# batch_size dimension will be added later on.\n","train_images = train_images[..., None]\n","test_images = test_images[..., None]\n","\n","# Normalize the images to [0, 1] range.\n","train_images = train_images / np.float32(255)\n","test_images = test_images / np.float32(255)\n","\n","# Batch the input data\n","BUFFER_SIZE = len(train_images)\n","BATCH_SIZE_PER_REPLICA = 64\n","GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","\n","# Create Datasets from the batches\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n","\n","# Create Distributed Datasets from the datasets\n","train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n","test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"Q4si-73dpo9K"},"source":["## Define the Model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"h4OLGFJypo9M","executionInfo":{"status":"ok","timestamp":1643272150671,"user_tz":-420,"elapsed":40,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}}},"outputs":[],"source":["# Create the model architecture\n","def create_model():\n","  model = tf.keras.Sequential([\n","      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","      tf.keras.layers.MaxPooling2D(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(64, activation='relu'),\n","      tf.keras.layers.Dense(10)\n","    ])\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"zTwhmTaQpo9N"},"source":["## Configure custom training\n","\n","Instead of `model.compile()`, we're going to do custom training, so let's do that within a strategy scope."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KdUs7hlpo9O","executionInfo":{"status":"ok","timestamp":1643272150673,"user_tz":-420,"elapsed":36,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}},"outputId":"e36559dc-7beb-4318-dd88-20925d366dfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"]}],"source":["with strategy.scope():\n","    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n","    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n","    # Remember -- the map reduce is how the losses get aggregated\n","    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n","\n","    def compute_loss(labels, predictions):\n","        # Compute Loss uses the loss object to compute the loss\n","        # Notice that per_example_loss will have an entry per GPU\n","        # so in this case there'll be 2 -- i.e. the loss for each replica\n","        per_example_loss = loss_object(labels, predictions)\n","        # You can print it to see it -- you'll get output like this:\n","        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n","        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n","        print(per_example_loss)\n","        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n","\n","    # We'll just reduce by getting the average of the losses\n","    test_loss = tf.keras.metrics.Mean(name='test_loss')\n","\n","    # Accuracy on train and test will be SparseCategoricalAccuracy\n","    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","    # Optimizer will be Adam\n","    optimizer = tf.keras.optimizers.Adam()\n","\n","    # Create the model within the scope\n","    model = create_model()"]},{"cell_type":"markdown","metadata":{"id":"tj1MrW1ipo9Q"},"source":["## Train and Test Steps Functions\n","\n","Let's define a few utilities to facilitate the training."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"k0VOdqKP2NEz","executionInfo":{"status":"ok","timestamp":1643272150675,"user_tz":-420,"elapsed":23,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}}},"outputs":[],"source":["# `run` replicates the provided computation and runs it\n","# with the distributed input.\n","@tf.function\n","def distributed_train_step(dataset_inputs):\n","  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n","  #tf.print(per_replica_losses.values)\n","  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n","\n","def train_step(inputs):\n","  images, labels = inputs\n","  with tf.GradientTape() as tape:\n","    predictions = model(images, training=True)\n","    loss = compute_loss(labels, predictions)\n","\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_accuracy.update_state(labels, predictions)\n","  return loss\n","\n","#######################\n","# Test Steps Functions\n","#######################\n","@tf.function\n","def distributed_test_step(dataset_inputs):\n","  return strategy.run(test_step, args=(dataset_inputs,))\n","\n","def test_step(inputs):\n","  images, labels = inputs\n","\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss.update_state(t_loss)\n","  test_accuracy.update_state(labels, predictions)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XTGrOfClpo9U"},"source":["## Training Loop\n","\n","We can now start training the model."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrvxGXIWpo9V","executionInfo":{"status":"ok","timestamp":1643272253362,"user_tz":-420,"elapsed":102707,"user":{"displayName":"Lộc Bảo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406170824357259025"}},"outputId":"ad8499fc-dde3-431f-efde-bd8f36687d3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n","Epoch 1, Loss: 0.5033201575279236, Accuracy: 81.7300033569336, Test Loss: 0.37886860966682434, Test Accuracy: 86.63999938964844\n","Epoch 2, Loss: 0.3326878547668457, Accuracy: 87.961669921875, Test Loss: 0.35065141320228577, Test Accuracy: 87.43000030517578\n","Epoch 3, Loss: 0.2875288426876068, Accuracy: 89.53166961669922, Test Loss: 0.30139705538749695, Test Accuracy: 89.30000305175781\n","Epoch 4, Loss: 0.25656893849372864, Accuracy: 90.62166595458984, Test Loss: 0.2824891209602356, Test Accuracy: 89.7300033569336\n","Epoch 5, Loss: 0.23292525112628937, Accuracy: 91.44833374023438, Test Loss: 0.28032591938972473, Test Accuracy: 90.0\n","Epoch 6, Loss: 0.21495449542999268, Accuracy: 92.09832763671875, Test Loss: 0.26014018058776855, Test Accuracy: 90.55000305175781\n","Epoch 7, Loss: 0.19755150377750397, Accuracy: 92.61666870117188, Test Loss: 0.2931421101093292, Test Accuracy: 88.99000549316406\n","Epoch 8, Loss: 0.1823243796825409, Accuracy: 93.23833465576172, Test Loss: 0.248200923204422, Test Accuracy: 90.95999908447266\n","Epoch 9, Loss: 0.1666579395532608, Accuracy: 93.97833251953125, Test Loss: 0.26992374658584595, Test Accuracy: 90.77999877929688\n","Epoch 10, Loss: 0.15459541976451874, Accuracy: 94.31499481201172, Test Loss: 0.25095099210739136, Test Accuracy: 91.30999755859375\n"]}],"source":["EPOCHS = 10\n","for epoch in range(EPOCHS):\n","  # Do Training\n","  total_loss = 0.0\n","  num_batches = 0\n","  for batch in train_dist_dataset:\n","    total_loss += distributed_train_step(batch)\n","    num_batches += 1\n","  train_loss = total_loss / num_batches\n","\n","  # Do Testing\n","  for batch in test_dist_dataset:\n","    distributed_test_step(batch)\n","\n","  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n","\n","  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n","\n","  test_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_accuracy.reset_states()"]}],"metadata":{"colab":{"name":"C2_W4_Lab_2_multi-GPU-mirrored-strategy.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}